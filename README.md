# TTS FastSpeech2

## 1. Download model

Download the model from https://huggingface.co/facebook/fastspeech2-en-ljspeech and put all model files
in `./fastspeech2-en-ljspeech` directory which under the current directory. The directory structure is as follows


```text
./fastspeech2-en-ljspeech
├── README.md
├── config.yaml
├── fbank_mfa_gcmvn_stats.npz
├── hifigan.bin
├── hifigan.json
├── pytorch_model.pt
├── run_fast_speech_2.py
└── vocab.txt
```

## 2. Preparation

### 2.1 Python requirements

Install the python packages necessary for the service, listed in `requirements.txt`. 

```shell
pip install -r ./requirements.txt
```

### 2.2 NLTK files

The model prediction requires nltk's `cmudict.zip` and `averaged_perceptron_tagger.zip`. Due to the unstable network, manually download these compressed packages by yourself.
Download archives from https://github.com/nltk/nltk_data/tree/gh-pages/packages and put them in `3rdparty/nltk` under the current directory, the directory is as follows:

```text
3rdparty
└── nltk
    ├── corpora
    │   ├── cmudict
    │   │   ├── README
    │   │   └── cmudict
    │   └── cmudict.zip
    └── taggers
        ├── averaged_perceptron_tagger
        │   └── averaged_perceptron_tagger.pickle
        └── averaged_perceptron_tagger.zip
```

Now, current directory should contain these files and directories:
```text
├── 3rdparty
├── README.md
├── client.py
├── create_mar.sh
├── fastspeech2-en-ljspeech
├── handler.py
├── requirements.txt
└── start_ts.sh
```

## 3. Create TorchServe Model Archiver File

```shell
bash ./create_mar.sh
```
After waiting for a while, we got the mar file needed for the service. Then we can start our service.

## 4. Start TorchServe

Now you can start service with below command.
```shell
bash start_ts.sh
```

## 5. Test Service

Request the service in the terminal, execute 
```shell
python client.py
```
When you see 'Successfully generated output_client.wav', indicating that the requested service is successful. In the current directory, you can find the file `output_client.wav`, open it, and you can hear the voice generated by the model.